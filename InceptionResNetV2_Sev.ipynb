{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionResNetV2_Sev.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhinavRobinson/TheKaggleProject/blob/master/InceptionResNetV2_Sev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuaU5vDiFpuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Concatenate, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers, activations\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueZoCDqFGAYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_crop(img, random_crop_size): \n",
        "    # Note: image_data_format is ‘channel_last’ \n",
        "    h, w = img.shape[0], img.shape[1] \n",
        "    dy, dx = random_crop_size \n",
        "    x = np.random.randint(0, w — dx + 1) \n",
        "    y = np.random.randint(0, h — dy + 1) \n",
        "    return img[y:(y+dy), x:(x+dx), :] \n",
        "def crop_generator(batches, crop_length): \n",
        "    # Take as input a Keras ImageGen (Iterator) \n",
        "    # and generate random crops from the image batches \n",
        "    # generated by the original iterator. \n",
        "    sz = crop_length \n",
        "    while True: \n",
        "        batch_x, batch_y = next(batches) \n",
        "        batch_crops = np.zeros((batch_x.shape[0], sz, sz, 3)) \n",
        "        for i in range(batch_x.shape[0]): \n",
        "            batch_crops[i] = random_crop(batch_x[i], (sz,sz))\n",
        "        yield (batch_crops, batch_y)\n",
        "\n",
        "tr_datagen =  ImageDataGenerator(rescale=1.0/255, \n",
        "                                 horizontal_flip=True,\n",
        "                                 vertical_flip=True)\n",
        "ts_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# SET ARGUMENTS ****TODO****\n",
        "\n",
        "# train_path = \n",
        "# train_batch_size = \n",
        "# val_batch_size =\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_gen = tr_datagen.flow_from_directory(train_path,\n",
        "                                target_size=(IMAGE_SIZE_WIDTH,IMAGE_SIZE_HEIGHT),\n",
        "                                batch_size=train_batch_size,\n",
        "                                class_mode=’categorical’)\n",
        "tr_crops = crop_generator(train_gen)\n",
        "val_gen = ts_datagen.flow_from_directory(valid_path,\n",
        "                               target_size=(IMAGE_SIZE_WIDTH,IMAGE_SIZE_HEIGHT),\n",
        "                               batch_size=val_batch_size,\n",
        "                               class_mode=’categorical’)\n",
        "val_crops = crop_generator(val_gen)\n",
        "#Note: shuffle=False causes the test dataset to not be shuffled\n",
        "test_gen = ts_datagen.flow_from_directory(valid_path,\n",
        "                               target_size=(IMAGE_SIZE_WIDTH,IMAGE_SIZE_HEIGHT),\n",
        "                               batch_size=1,\n",
        "                               class_mode=’categorical’,\n",
        "                               shuffle=False)\n",
        "#ts_crops = crop_generator(test_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eelex1ibGFj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d(x,numfilt,filtsz,strides=1,pad='same',act=True,name=None):\n",
        "  x = Conv2D(numfilt,filtsz,strides,padding=pad,data_format='channels_last',use_bias=False,name=name+'conv2d')(x)\n",
        "  x = BatchNormalization(axis=3,scale=False,name=name+'conv2d'+'bn')(x)\n",
        "  if act:\n",
        "    x = Activation('relu',name=name+'conv2d'+'act')(x)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOrx1h0ZGIAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def incresA(x,scale,name=None):\n",
        "    pad = 'same'\n",
        "    branch0 = conv2d(x,32,1,1,pad,True,name=name+'b0')\n",
        "    branch1 = conv2d(x,32,1,1,pad,True,name=name+'b1_1')\n",
        "    branch1 = conv2d(branch1,32,3,1,pad,True,name=name+'b1_2')\n",
        "    branch2 = conv2d(x,32,1,1,pad,True,name=name+'b2_1')\n",
        "    branch2 = conv2d(branch2,48,3,1,pad,True,name=name+'b2_2')\n",
        "    branch2 = conv2d(branch2,64,3,1,pad,True,name=name+'b2_3')\n",
        "    branches = [branch0,branch1,branch2]\n",
        "    mixed = Concatenate(axis=3, name=name + '_concat')(branches)\n",
        "    filt_exp_1x1 = conv2d(mixed,384,1,1,pad,False,name=name+'filt_exp_1x1')\n",
        "    final_lay = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
        "                      output_shape=backend.int_shape(x)[1:],\n",
        "                      arguments={'scale': scale},\n",
        "                      name=name+'act_scaling')([x, filt_exp_1x1])\n",
        "    return final_lay"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhFEfYCIGKCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def incresB(x,scale,name=None):\n",
        "    pad = 'same'\n",
        "    branch0 = conv2d(x,192,1,1,pad,True,name=name+'b0')\n",
        "    branch1 = conv2d(x,128,1,1,pad,True,name=name+'b1_1')\n",
        "    branch1 = conv2d(branch1,160,[1,7],1,pad,True,name=name+'b1_2')\n",
        "    branch1 = conv2d(branch1,192,[7,1],1,pad,True,name=name+'b1_3')\n",
        "    branches = [branch0,branch1]\n",
        "    mixed = Concatenate(axis=3, name=name + '_mixed')(branches)\n",
        "    filt_exp_1x1 = conv2d(mixed,1152,1,1,pad,False,name=name+'filt_exp_1x1')\n",
        "    final_lay = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
        "                      output_shape=backend.int_shape(x)[1:],\n",
        "                      arguments={'scale': scale},\n",
        "                      name=name+'act_scaling')([x, filt_exp_1x1])\n",
        "    return final_lay"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IlyfxDhGSFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def incresC(x,scale,name=None):\n",
        "    pad = 'same'\n",
        "    branch0 = conv2d(x,192,1,1,pad,True,name=name+'b0')\n",
        "    branch1 = conv2d(x,192,1,1,pad,True,name=name+'b1_1')\n",
        "    branch1 = conv2d(branch1,224,[1,3],1,pad,True,name=name+'b1_2')\n",
        "    branch1 = conv2d(branch1,256,[3,1],1,pad,True,name=name+'b1_3')\n",
        "    branches = [branch0,branch1]\n",
        "    mixed = Concatenate(axis=3, name=name + '_mixed')(branches)\n",
        "    filt_exp_1x1 = conv2d(mixed,2048,1,1,pad,False,name=name+'fin1x1')\n",
        "    final_lay = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
        "                      output_shape=backend.int_shape(x)[1:],\n",
        "                      arguments={'scale': scale},\n",
        "                      name=name+'act_saling')([x, filt_exp_1x1])\n",
        "    return final_lay"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aoPEpXBGVnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# **********TODO********** \n",
        "img_input = Input(shape=(32,32,3))\n",
        "\n",
        "x = conv2d(img_input,32,3,2,'valid',True,name='conv1')\n",
        "x = conv2d(x,32,3,1,'valid',True,name='conv2')\n",
        "x = conv2d(x,64,3,1,'valid',True,name='conv3')\n",
        "\n",
        "x_11 = MaxPooling2D(3,strides=1,padding='valid',name='stem_br_11'+'_maxpool_1')(x)\n",
        "x_12 = conv2d(x,64,3,1,'valid',True,name='stem_br_12')\n",
        "\n",
        "x = Concatenate(axis=3, name = 'stem_concat_1')([x_11,x_12])\n",
        "\n",
        "x_21 = conv2d(x,64,1,1,'same',True,name='stem_br_211')\n",
        "x_21 = conv2d(x_21,64,[1,7],1,'same',True,name='stem_br_212')\n",
        "x_21 = conv2d(x_21,64,[7,1],1,'same',True,name='stem_br_213')\n",
        "x_21 = conv2d(x_21,96,3,1,'valid',True,name='stem_br_214')\n",
        "\n",
        "x_22 = conv2d(x,64,1,1,'same',True,name='stem_br_221')\n",
        "x_22 = conv2d(x_22,96,3,1,'valid',True,name='stem_br_222')\n",
        "\n",
        "x = Concatenate(axis=3, name = 'stem_concat_2')([x_21,x_22])\n",
        "\n",
        "x_31 = conv2d(x,192,3,1,'valid',True,name='stem_br_31')\n",
        "x_32 = MaxPooling2D(3,strides=1,padding='valid',name='stem_br_32'+'_maxpool_2')(x)\n",
        "x = Concatenate(axis=3, name = 'stem_concat_3')([x_31,x_32])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZBEh3KCGZH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Inception-ResNet-A modules\n",
        "x = incresA(x,0.15,name='incresA_1')\n",
        "x = incresA(x,0.15,name='incresA_2')\n",
        "x = incresA(x,0.15,name='incresA_3')\n",
        "x = incresA(x,0.15,name='incresA_4')\n",
        "\n",
        "#35 × 35 to 17 × 17 reduction module.\n",
        "x_red_11 = MaxPooling2D(3,strides=2,padding='valid',name='red_maxpool_1')(x)\n",
        "\n",
        "x_red_12 = conv2d(x,384,3,2,'valid',True,name='x_red1_c1')\n",
        "\n",
        "x_red_13 = conv2d(x,256,1,1,'same',True,name='x_red1_c2_1')\n",
        "x_red_13 = conv2d(x_red_13,256,3,1,'same',True,name='x_red1_c2_2')\n",
        "x_red_13 = conv2d(x_red_13,384,3,2,'valid',True,name='x_red1_c2_3')\n",
        "\n",
        "x = Concatenate(axis=3, name='red_concat_1')([x_red_11,x_red_12,x_red_13])\n",
        "\n",
        "#Inception-ResNet-B modules\n",
        "x = incresB(x,0.1,name='incresB_1')\n",
        "x = incresB(x,0.1,name='incresB_2')\n",
        "x = incresB(x,0.1,name='incresB_3')\n",
        "x = incresB(x,0.1,name='incresB_4')\n",
        "x = incresB(x,0.1,name='incresB_5')\n",
        "x = incresB(x,0.1,name='incresB_6')\n",
        "x = incresB(x,0.1,name='incresB_7')\n",
        "\n",
        "#17 × 17 to 8 × 8 reduction module.\n",
        "x_red_21 = MaxPooling2D(3,strides=2,padding='valid',name='red_maxpool_2')(x)\n",
        "\n",
        "x_red_22 = conv2d(x,256,1,1,'same',True,name='x_red2_c11')\n",
        "x_red_22 = conv2d(x_red_22,384,3,2,'valid',True,name='x_red2_c12')\n",
        "\n",
        "x_red_23 = conv2d(x,256,1,1,'same',True,name='x_red2_c21')\n",
        "x_red_23 = conv2d(x_red_23,256,3,2,'valid',True,name='x_red2_c22')\n",
        "\n",
        "x_red_24 = conv2d(x,256,1,1,'same',True,name='x_red2_c31')\n",
        "x_red_24 = conv2d(x_red_24,256,3,1,'same',True,name='x_red2_c32')\n",
        "x_red_24 = conv2d(x_red_24,256,3,2,'valid',True,name='x_red2_c33')\n",
        "\n",
        "x = Concatenate(axis=3, name='red_concat_2')([x_red_21,x_red_22,x_red_23,x_red_24])\n",
        "\n",
        "#Inception-ResNet-C modules\n",
        "x = incresC(x,0.2,name='incresC_1')\n",
        "x = incresC(x,0.2,name='incresC_2')\n",
        "x = incresC(x,0.2,name='incresC_3')\n",
        "\n",
        "#TOP\n",
        "x = GlobalAveragePooling2D(data_format='channels_last')(x)\n",
        "x = Dropout(0.6)(x)\n",
        "x = Dense(num_classes, activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1FsH55tGg5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(img_input,x,name=’inception_resnet_v2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_j7eg2rGh66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyk7mGqhGj-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import SVG\n",
        "\n",
        "plot_model(model, to_file=’model_plot.png’, \n",
        "                  show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zHcdMrHGlTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(Adam(lr=0.0001), \n",
        "              loss=’categorical_crossentropy’,\n",
        "              metrics=[‘accuracy’])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34wd1zgmGnHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = “model.h5”\n",
        "checkpoint = ModelCheckpoint(filepath, monitor=’val_acc’, \n",
        "                        verbose=1, save_best_only=True, mode=’max’)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwzSQ8AUGpWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early = EarlyStopping(monitor=\"val_loss\", \n",
        "                      mode=\"min\", \n",
        "                      patience=4, restore_best_weights=True)\n",
        "callbacks_list = [checkpoint, early]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMhVNM2QGq4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_gen,\n",
        "                              steps_per_epoch=train_steps,          \n",
        "                              validation_data=val_gen,\n",
        "                              validation_steps=val_steps, \n",
        "                              epochs=20, verbose=1,\n",
        "                              callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siH1jdyGGrm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training plots\n",
        "epochs = [i for i in range(1, len(history.history['loss'])+1)]\n",
        "\n",
        "plt.plot(epochs, history.history['loss'], color='blue', label=\"training_loss\")\n",
        "plt.plot(epochs, history.history['val_loss'], color='red', label=\"validation_loss\")\n",
        "plt.legend(loc='best')\n",
        "plt.title('training')\n",
        "plt.xlabel('epoch')\n",
        "plt.savefig(TRAINING_PLOT_FILE, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, history.history['acc'], color='blue', label=\"training_accuracy\")\n",
        "plt.plot(epochs, history.history['val_acc'], color='red',label=\"validation_accuracy\")\n",
        "plt.legend(loc='best')\n",
        "plt.title('validation')\n",
        "plt.xlabel('epoch')\n",
        "plt.savefig(VALIDATION_PLOT_FILE, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8sbOE1UGtJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make sure to load the best model\n",
        "model.load_weights('model.h5')\n",
        "\n",
        "predictions = model.predict_generator(test_gen, \n",
        "                                      steps=num_test_images, \n",
        "                                      verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}